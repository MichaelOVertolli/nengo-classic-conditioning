{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pylab\n",
    "import nengo\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nengo.Network(seed=3)\n",
    "SIM_TIME = 50\n",
    "SWITCH_TIME = 500\n",
    "SWITCH_TIME2 = 50\n",
    "SIM_TIME2 = SWITCH_TIME2*0.001\n",
    "def fn(j, vals, vals2):\n",
    "    s = SWITCH_TIME\n",
    "    vs = vals\n",
    "    t = 0\n",
    "    cur = 0\n",
    "    i = 0\n",
    "    while True:\n",
    "    #initial training\n",
    "        if t >= SIM_TIME:\n",
    "            break\n",
    "        j.append(vs[i])\n",
    "        t = yield [vs[i], 0, 1]\n",
    "        if t-cur >= 0.001*(s-1):\n",
    "            cur = t\n",
    "            i += 1\n",
    "    s = SWITCH_TIME2\n",
    "    vs = vals2\n",
    "    i = 0\n",
    "    cur = t\n",
    "    while True:\n",
    "    #assessment 1\n",
    "        if i >= len(vals2):\n",
    "            print 'too far'\n",
    "            break\n",
    "        j.append(vs[i])\n",
    "        t = yield [vs[i], 0, 0]\n",
    "        if t-cur >= 0.001*(s-1):\n",
    "            cur = t\n",
    "            i += 1\n",
    "    while True:\n",
    "        t = yield [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist = nengo.dists.Uniform(-1.0, 1.0)\n",
    "vals = dist.sample((1000*SIM_TIME/SWITCH_TIME)+1)\n",
    "vals2 = np.linspace(-1, 1, 45)\n",
    "j=[]\n",
    "func = fn(j, vals, vals2)\n",
    "func.next()\n",
    "func = func.send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    stim = nengo.Node(func)\n",
    "    \n",
    "    sensory = nengo.Ensemble(n_neurons=200, dimensions=3,\n",
    "                            intercepts=nengo.dists.Uniform(0.87,0.91))\n",
    "    \n",
    "    \n",
    "    spatial = nengo.Ensemble(n_neurons=200, dimensions=2,\n",
    "                            intercepts=nengo.dists.Uniform(0.87,0.91))\n",
    "    \n",
    "    nengo.Connection(stim, sensory[:],\n",
    "                     function=lambda x: (np.sin(x[0]*np.pi/2), \n",
    "                                         np.cos(x[0]*np.pi/2), \n",
    "                                         x[1]))\n",
    "    \n",
    "    #nengo.Connection(sensory[:2], sensory[2:], synapse=0.2)\n",
    "    \n",
    "    c = nengo.Connection(sensory, spatial, function=lambda x: [0,0],\n",
    "                         learning_rule_type=nengo.PES(learning_rate=3e-4))\n",
    "        \n",
    "    error = nengo.Ensemble(n_neurons=100, dimensions=3)\n",
    "    \n",
    "    nengo.Connection(stim[2], error[2])\n",
    "    nengo.Connection(sensory[:2], error[:2],\n",
    "                     transform=-1)\n",
    "    nengo.Connection(error, c.learning_rule, \n",
    "                     function=lambda x: x[:2] if x[2] > 0.5 else [0, 0])\n",
    "    #nengo.Connection(spatial, c.learning_rule, synapse=0.1)\n",
    "    \n",
    "    nengo.Connection(spatial, error[:2])\n",
    "    #correct = nengo.Node([0,0])\n",
    "    #nengo.Connection(correct, error, transform=-1)\n",
    "    \n",
    "    error_probe = nengo.Probe(error)\n",
    "    spatial_probe = nengo.Probe(spatial.neurons)\n",
    "    spatial_probe_v = nengo.Probe(spatial)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished in 0:00:31.                                                 \n"
     ]
    }
   ],
   "source": [
    "sim = nengo.Simulator(model)\n",
    "sim.run(SIM_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sim_gen(time, cnt):\n",
    "    cur = 0\n",
    "    while cur < cnt:\n",
    "        yield np.mean(sim.data[spatial_probe][-SWITCH_TIME2:], axis=0)\n",
    "        print sim.data[spatial_probe].shape\n",
    "        sim.run(time)\n",
    "        cur += 1\n",
    "        \n",
    "def calc_norm(rates):\n",
    "    #assume that cells with similar peak centers would fall under the same\n",
    "    #multicellular recording therefore peaks are done relative to all values with similar peaks\n",
    "    nrm_rates = []\n",
    "    rate_peaks = np.max(rates, axis=1)\n",
    "    max_i = np.argmax(rates, axis=0)\n",
    "    for j, i in enumerate(max_i):\n",
    "        nrm_rates.append(rates[:, j]/rate_peaks[i])\n",
    "    nrm_rates = np.array(nrm_rates).transpose()\n",
    "    return nrm_rates\n",
    "\n",
    "def align_cut(nrm, dist, num_checks):\n",
    "    #below uses the protocol from the paper where the center value of the values with >= 50% of\n",
    "    #the max value is used as the max\n",
    "    #cut assumes that it is not multimodal\n",
    "    cut = [[(i, neuron_val) for i, neuron_val in enumerate(nrm[:, col]) \n",
    "            if neuron_val >= 0.5] for col in range(nrm.shape[1])]\n",
    "    maxes = [(i, neuron_vals[len(neuron_vals)/2][0]) \n",
    "             for i, neuron_vals in enumerate(cut) \n",
    "             if len(neuron_vals) > 0]\n",
    "    max_cuts = [nrm[mx-dist:mx+dist+1, i] \n",
    "                for i, mx in maxes \n",
    "                if mx >= dist and mx <= num_checks-(dist+1)]\n",
    "    return np.array(max_cuts)\n",
    "\n",
    "def prep_graph(time, cnt, dist):\n",
    "    sim_g = sim_gen(time, cnt)\n",
    "    sim_g.next()\n",
    "    return align_cut(calc_norm(np.array([mean for mean in sim_g])), dist)\n",
    "\n",
    "def graph_neurons(vals, step):\n",
    "    for v in range(vals.shape[0]):\n",
    "        pylab.plot(range(-DIST*step, (DIST+1)*step, step), vals[v, :])\n",
    "\n",
    "def graph_mean(mean, step):\n",
    "    pylab.plot(range(-DIST*step, (DIST+1)*step, step), mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(50000, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50050, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50100, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50150, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50200, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50250, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50300, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50350, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50400, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50450, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50500, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50550, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50600, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50650, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50700, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50750, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50800, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50850, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50900, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(50950, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51000, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51050, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51100, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51150, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51200, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51250, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51300, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51350, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51400, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51450, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51500, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51550, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51600, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51650, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51700, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51750, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51800, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51850, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51900, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(51950, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(52000, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(52050, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(52100, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(52150, 200)\n",
      "Simulation finished in 0:00:01.                                                 \n",
      "(52200, 200)\n",
      "too far\n",
      "Simulation finished in 0:00:01.                                                 \n"
     ]
    }
   ],
   "source": [
    "sim_g = sim_gen(SIM_TIME2, len(vals2))\n",
    "a=sim_g.next()\n",
    "print a.shape\n",
    "mean = np.array([mean for mean in sim_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/ipykernel/__main__.py:16: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "n = calc_norm(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIST = 10\n",
    "out = align_cut(n, DIST, len(vals2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 200)\n",
      "(44, 200)\n",
      "(45,)\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "[  0.    2.   17.   31.3  22.6  12.    9.2  13.4  12.7  13.6  10.9   7.\n",
      "  27.7  33.9  10.6  15.2  36.6  48.4  60.6  38.4  30.    3.7  15.1  12.6\n",
      "   3.2   3.3  29.1  37.3  28.3  16.8  10.1  12.6  11.3  25.5  47.8  34.4\n",
      "  16.   16.7  28.4  20.4  30.5  27.8  25.8  22.3]\n"
     ]
    }
   ],
   "source": [
    "print mean.shape\n",
    "print n.shape\n",
    "print out.shape\n",
    "print [len(x) for x in out]\n",
    "print np.mean(mean[:, :], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71236197492622977, 0.71236197492622977, 0.71236197492622977]\n",
      "-0.237875359683\n",
      "0.712361974926\n",
      "52251\n",
      "[-0.33712848776146598, 0.34189185337210581, -0.23787535968306628, 0.71236197492622977, -0.67184923623671966, -0.99623902934628483, -0.19089636377871355, 0.22225663249388927, -0.43185899405533235, -0.19963889422006309, 0.72703120435681412, 0.86809876074649361, -0.4324228862876407, -0.84155977820803773, -0.74357352294855517, -0.28669169789954929, -0.5571239433288917, -0.69944589409294067, 0.9444337486349943, 0.57760630185501771, 0.60996459350334997, 0.37345430846058969, -0.73470639741538868, 0.082559886701077501, -0.63257732318345061, -0.42616903318514243, 0.19385811730140512, 0.46092814635418455, 0.24594352429433308, -0.72688104320700653, -0.37218109982644609, -0.52921557012783826, 0.83758361202627407, -0.056735157931992575, 0.51682563891840672, 0.63974274622605964, -0.47806422674195503, 0.52296916252519243, 0.56343562061417529, -0.69599931020541339, -0.61941355940636944, -0.17121635490345133, 0.18922052062761963, 0.74581749834522304, 0.59969947036552784, 0.82469851057322163, 0.22180987569442423, -0.97427075320871004, 0.46494147570440014, -0.83150556871854286, 0.18136757774144341, 0.40252484084511386, -0.023103293582822815, -0.4167804403254054, -0.043932295304899949, 0.032059488560400196, -0.24945330103856933, 0.33175644820013828, 0.028225223810830036, -0.96774259846051813, 0.9042022264615881, 0.71953811505451326, -0.86351368530429773, 0.6239539005876451, -0.0035311816569323362, 0.13290893812713533, -0.91353528006745277, 0.17845778685667013, -0.47657156667304967, -0.99581444714034428, -0.27655487532065148, -0.98354799142134475, -0.55109176750524536, 0.022248111363655676, 0.034959968915352801, 0.22571748251589274, 0.73370786785624253, 0.40144641501279166, 0.25458941070014585, -0.71568464884761385, 0.29913700703365342, -0.017744716821995743, -0.06425878403272911, -0.33516691146916844, -0.4356806150930741, -0.99716215213707926, -0.71227526213442927, -0.40498099681796962, 0.16755658438934673, 0.06503972684589443, 0.80774164311341057, 0.915720131429552, 0.45099721761062495, -0.876568275861076, 0.019771761291583534, 0.97874167894005537, -0.80878749926526794, 0.73120985572398989, 0.25987352779628048, -0.12218302237559131]\n",
      "0.157688619935 11\n",
      "-0.431858994055 499\n",
      "-0.190896363779 499\n",
      "0.222256632494 499\n",
      "-0.996239029346 499\n",
      "-0.237875359683 499\n",
      "0.341891853372 499\n",
      "-0.557123943329 499\n",
      "-0.913535280067 499\n",
      "0.0222481113637 499\n",
      "0.132908938127 499\n",
      "0.157688619935\n",
      "-0.337128487761\n"
     ]
    }
   ],
   "source": [
    "#print j[-(50*45+1):-(50*43)]\n",
    "print j[1502:1505]\n",
    "print j[1002]\n",
    "print j[1503]\n",
    "print len(j)\n",
    "#print [(j[i*500+2],np.mean(j[i*500+2:(i+1)*500+2])) for i in range(100)]\n",
    "print [j[:500*100+1][i*500+3] for i in range(100)]\n",
    "d = {}\n",
    "for a in set(j[:50001]):\n",
    "    d[a] = 0\n",
    "for a in j[:50001]:\n",
    "    d[a] += 1\n",
    "for k in d:\n",
    "    if d[k] != 500:\n",
    "        print k, d[k]\n",
    "print j[:50001][-1]\n",
    "print j[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 200)\n"
     ]
    }
   ],
   "source": [
    "graph_neurons(vals, STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_mean(mean_vals, STEP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
